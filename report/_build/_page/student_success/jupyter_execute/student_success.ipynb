{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict students' dropout and academic success\n",
    "\n",
    "by Katherine Chen, Hancheng Qin, Yili Tang, Bill Wan\n",
    "2023/12/02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from myst_nb import glue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In our study, we developed machine learning models, including SVM, Random Forest, and Logistic Regression (with L1 and L2 regularization), to predict the likelihood of student academic dropout in higher education. Due to a high number of features and their inter-correlations, our models initially exhibited overfitting. To address this, we implemented feature selection techniques (PCA and feature importance analysis) along with model's parameter optimization. The refined models demonstrated improved performance, evidenced by a narrow gap between training and testing accuracy. Among the three, SVM marginally outperformed the others, achieving an accuracy of 80% and an AUC score of 0.89. Nonetheless, there is potential for further enhancement in model performance through additional feature engineering and more extensive parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the realm of educational analytics, understanding the factors that influence student performance is pivotal for shaping effective pedagogical strategies. Our project delves into this domain, leveraging the rich and multifaceted Student Performance Data Set from the UCI Machine Learning Repository {cite}`misc_student_performance_320`. This dataset, derived from two Portuguese secondary schools, offers a comprehensive view of various personal, social, and academic factors impacting student achievement in Mathematics and Portuguese language courses.\n",
    "\n",
    "Machine learning methodologies have been extensively used in educational data mining to detect patterns in large collections of educational data {cite}`EducationalDataMining2015`. Our objective is to utilize machine learning techniques to analyze and predict student academic outcomes, focusing primarily on identifying key predictors of success and risk factors for academic dropout. Through this analysis, we aim to uncover insights that can guide interventions and support mechanisms to enhance student performance. The dataset's inclusivity of attributes ranging from demographic backgrounds and family information to study habits and lifestyle choices provides a unique opportunity to explore the multifaceted nature of academic success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### Data\n",
    "The data set used in this project is of student performance in secondary education (high school) of two Portuguese schools {cite}`misc_student_performance_320`. The data attributes include student grades, demographic, social and school related features, and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics and Portuguese language. The data set was sourced from the UCI Machine Learning Repository and can be found [here] (https://archive.ics.uci.edu/dataset/320/student+performance). Each row in the data set represents a studentâ€™s profile and academic outcomes, including the final grade (G3) and several other variables (e.g., school, sex, age, study time, absences, etc.).\n",
    "\n",
    "### Analysis\n",
    "The method we use include Random Forest, Logistic Regression, and SVM. In the landscape of machine learning, three algorithms stand out for their efficacy and versatility: Logistic Regression, Random Forest, and Support Vector Machine (SVM). We have employed the method of feature importance values and Principal Component Analysis (PCA) to streamline the dimensionality of our feature space. Data was split with 80% being partitioned into the training set and 20% being partitioned into the test set. The hyperparameter $K$ was chosen using 10-fold cross validation with the test score as the classification metric.  All numerical variables were standardized and categorical features were preprocessed by one-hot encoding just prior to model fitting. The Python programming language {cite}`Python`.  code used to perform the analysis and create this report can be found here: https://github.com/UBC-MDS/Student_Success_Predict_Group15. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Discussion\n",
    "\n",
    "To examine the potential of each predictor in forecasting student performance, we plotted the distributions of each predictor from the training data set and coloured the distribution by target class (graduate: green, dropout: orange, enroller: blue). In doing this we see that class distributions for most of the predictors overlap somewhat, but do show quite a difference in their centres and spreads. In particular, we come up with below observation in numeric features:\n",
    "1. Previous Qualification (Grade) and Admission Grade: Both these variables have similar ranges (min 95 to max 190), indicating a possible correlation between previous academic performance and admission grades. The mean and median values are close, suggesting a relatively symmetric distribution for these variables.\n",
    "2. Age at Enrollment: The age range is quite broad (17 to 70 years), indicating a diverse set of students in terms of age. Transformation technique like Standardization is required\n",
    "3. Curricular Units Credited (1st and 2nd Semesters): The mean values for credited curricular units in both semesters are low (around 0.71 for the 1st semester and 0.54 for the 2nd), the 75% percentile is 0, suggesting that most students do not have many, if any, units credited. This could be because they are first year students.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are density plot of numerical variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/figures/density_of_numeric_feature.png\n",
    "---|\n",
    "width: 800px\n",
    "name: density_of_numeric_feature\n",
    "---\n",
    "Distributions comparison of numeric features between the Graduate, Dropout, and Enrolled groups.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While for categorical features, we come up with the below conclusion:\n",
    "1. Nationality: The majority are Portuguese, with a small representation from other nationalities.\n",
    "2. Parents' Occupation: Both mother's and father's occupations are coded numerically. The most common occupation code for mothers and fathers is Unskilled Workers. Be careful about the matrix sparsity issue.\n",
    "3. Debtor, Tuition Fees Up to Date, Scholarship Holder: There's a notable number of students who are debtors (397) or whose tuition fees are not up to date (419), while 871 are scholarship holders. These figures highlight the financial aspects and challenges faced by the student population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are histogram distribution plot of categorical variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/figures/distribution_of_categorical_feature.png\n",
    "---|\n",
    "width: 800px\n",
    "name: distribution_of_categorical_feature\n",
    "---\n",
    "Distribution comparison of categorical predictors between the Graduate, Dropout, and Enrolled groups.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also observed correlations between certain features. To visually represent these relationships, we employed a correlation heatmap. This heatmap reveals the strength of associations between different variables and aids in understanding how these variables collectively impact our subject of study:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/figures/heat_map.png\n",
    "---|\n",
    "width: 800px\n",
    "name: heat_map\n",
    "---\n",
    "Heatmap for correlation matrix.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.778531</td>\n",
       "      <td>0.783051</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.757904</td>\n",
       "      <td>0.766489</td>\n",
       "      <td>0.787877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.778531</td>\n",
       "      <td>0.783051</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.751311</td>\n",
       "      <td>0.764394</td>\n",
       "      <td>0.779679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.895952</td>\n",
       "      <td>0.894758</td>\n",
       "      <td>0.891939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  RandomForest  LogisticRegression       SVC\n",
       "0   accuracy      0.778531            0.783051  0.796610\n",
       "1  precision      0.757904            0.766489  0.787877\n",
       "2     recall      0.778531            0.783051  0.796610\n",
       "3         f1      0.751311            0.764394  0.779679\n",
       "4    roc_auc      0.895952            0.894758  0.891939"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "test_scores"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit_time</td>\n",
       "      <td>0.201609</td>\n",
       "      <td>0.075037</td>\n",
       "      <td>1.279907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>score_time</td>\n",
       "      <td>0.030778</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.203314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.757279</td>\n",
       "      <td>0.764905</td>\n",
       "      <td>0.757561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_accuracy</td>\n",
       "      <td>0.843599</td>\n",
       "      <td>0.782283</td>\n",
       "      <td>0.787652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.737193</td>\n",
       "      <td>0.745870</td>\n",
       "      <td>0.743182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_precision</td>\n",
       "      <td>0.850690</td>\n",
       "      <td>0.768551</td>\n",
       "      <td>0.779404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.757279</td>\n",
       "      <td>0.764905</td>\n",
       "      <td>0.757561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_recall</td>\n",
       "      <td>0.843599</td>\n",
       "      <td>0.782283</td>\n",
       "      <td>0.787652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_f1</td>\n",
       "      <td>0.731526</td>\n",
       "      <td>0.744275</td>\n",
       "      <td>0.739644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_f1</td>\n",
       "      <td>0.832972</td>\n",
       "      <td>0.764501</td>\n",
       "      <td>0.771922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.877215</td>\n",
       "      <td>0.869558</td>\n",
       "      <td>0.877458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>train_roc_auc</td>\n",
       "      <td>0.961276</td>\n",
       "      <td>0.892067</td>\n",
       "      <td>0.907815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  RandomForest  Logistic Regression       SVC\n",
       "0          fit_time      0.201609             0.075037  1.279907\n",
       "1        score_time      0.030778             0.019465  0.203314\n",
       "2     test_accuracy      0.757279             0.764905  0.757561\n",
       "3    train_accuracy      0.843599             0.782283  0.787652\n",
       "4    test_precision      0.737193             0.745870  0.743182\n",
       "5   train_precision      0.850690             0.768551  0.779404\n",
       "6       test_recall      0.757279             0.764905  0.757561\n",
       "7      train_recall      0.843599             0.782283  0.787652\n",
       "8           test_f1      0.731526             0.744275  0.739644\n",
       "9          train_f1      0.832972             0.764501  0.771922\n",
       "10     test_roc_auc      0.877215             0.869558  0.877458\n",
       "11    train_roc_auc      0.961276             0.892067  0.907815"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "training_scores"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_scores = pd.read_csv('../results/tables/test_scores.csv')\n",
    "training_scores = pd.read_csv('../results/tables/training_scores_cv.csv')\n",
    "glue(\"test_scores\", test_scores)\n",
    "glue(\"training_scores\", training_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final models demonstrated commendable performance, marked by a minimal discrepancy between training and testing results. This consistency is indicative of the models' ability to generalize well to unseen data, a crucial aspect of robust machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} training_scores\n",
    "---\n",
    "width: 400px\n",
    "name: model_training_scores\n",
    "---\n",
    "Training scores for the three models: Logistic Regression, Random Forest, and Support Vector Machine.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Among the three algorithms employed - Logistic Regression, Random Forest, and Support Vector Machine (SVM) - the performance metrics were closely aligned, suggesting that each model was able to capture the underlying patterns in the data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glue:figure} test_scores\n",
    "---\n",
    "width: 400px\n",
    "name: model_test_scores\n",
    "---\n",
    "Test scores for the three models: Logistic Regression, Random Forest, and Support Vector Machine.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there remains room for improvement in the models' performance. Further refinement through advanced feature engineering could yield more significant insights from the data, potentially enhancing the models' predictive accuracy. Feature engineering, by uncovering more relevant or representative features, can lead to a more nuanced understanding of the factors influencing student academic dropout. Moreover, meticulous parameter tuning, particularly for algorithms like SVM and Random Forest that are sensitive to specific parameter settings, could further optimize the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}